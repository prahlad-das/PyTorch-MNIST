{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torch.utils\n",
    "import torch.nn as nn\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = torchvision.datasets.MNIST(root='Data', train= True, transform=transforms.ToTensor(), download=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = torchvision.datasets.MNIST(root='Data', train= False, transform=transforms.ToTensor(), download=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 100\n",
    "learning_rate = 0.01\n",
    "input_size = 28*28\n",
    "num_classes = 10\n",
    "num_epochs = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader(dataset=train_data, batch_size=batch_size, shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(dataset=test_data, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = nn.Linear(input_size, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(params=model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/50], Step [100/600], Loss: 1.6066\n",
      "Epoch [1/50], Step [200/600], Loss: 1.1572\n",
      "Epoch [1/50], Step [300/600], Loss: 0.9661\n",
      "Epoch [1/50], Step [400/600], Loss: 0.7810\n",
      "Epoch [1/50], Step [500/600], Loss: 0.8082\n",
      "Epoch [1/50], Step [600/600], Loss: 0.7443\n",
      "Epoch [2/50], Step [100/600], Loss: 0.8395\n",
      "Epoch [2/50], Step [200/600], Loss: 0.5912\n",
      "Epoch [2/50], Step [300/600], Loss: 0.5917\n",
      "Epoch [2/50], Step [400/600], Loss: 0.7111\n",
      "Epoch [2/50], Step [500/600], Loss: 0.5630\n",
      "Epoch [2/50], Step [600/600], Loss: 0.5391\n",
      "Epoch [3/50], Step [100/600], Loss: 0.5448\n",
      "Epoch [3/50], Step [200/600], Loss: 0.5118\n",
      "Epoch [3/50], Step [300/600], Loss: 0.5008\n",
      "Epoch [3/50], Step [400/600], Loss: 0.4755\n",
      "Epoch [3/50], Step [500/600], Loss: 0.3961\n",
      "Epoch [3/50], Step [600/600], Loss: 0.4060\n",
      "Epoch [4/50], Step [100/600], Loss: 0.3975\n",
      "Epoch [4/50], Step [200/600], Loss: 0.6701\n",
      "Epoch [4/50], Step [300/600], Loss: 0.4990\n",
      "Epoch [4/50], Step [400/600], Loss: 0.5010\n",
      "Epoch [4/50], Step [500/600], Loss: 0.5182\n",
      "Epoch [4/50], Step [600/600], Loss: 0.4611\n",
      "Epoch [5/50], Step [100/600], Loss: 0.7383\n",
      "Epoch [5/50], Step [200/600], Loss: 0.5261\n",
      "Epoch [5/50], Step [300/600], Loss: 0.5517\n",
      "Epoch [5/50], Step [400/600], Loss: 0.4977\n",
      "Epoch [5/50], Step [500/600], Loss: 0.4197\n",
      "Epoch [5/50], Step [600/600], Loss: 0.4774\n",
      "Epoch [6/50], Step [100/600], Loss: 0.6089\n",
      "Epoch [6/50], Step [200/600], Loss: 0.3887\n",
      "Epoch [6/50], Step [300/600], Loss: 0.3404\n",
      "Epoch [6/50], Step [400/600], Loss: 0.5270\n",
      "Epoch [6/50], Step [500/600], Loss: 0.4484\n",
      "Epoch [6/50], Step [600/600], Loss: 0.5366\n",
      "Epoch [7/50], Step [100/600], Loss: 0.4164\n",
      "Epoch [7/50], Step [200/600], Loss: 0.3763\n",
      "Epoch [7/50], Step [300/600], Loss: 0.2722\n",
      "Epoch [7/50], Step [400/600], Loss: 0.4979\n",
      "Epoch [7/50], Step [500/600], Loss: 0.5248\n",
      "Epoch [7/50], Step [600/600], Loss: 0.4485\n",
      "Epoch [8/50], Step [100/600], Loss: 0.4589\n",
      "Epoch [8/50], Step [200/600], Loss: 0.3189\n",
      "Epoch [8/50], Step [300/600], Loss: 0.3630\n",
      "Epoch [8/50], Step [400/600], Loss: 0.4490\n",
      "Epoch [8/50], Step [500/600], Loss: 0.2787\n",
      "Epoch [8/50], Step [600/600], Loss: 0.3074\n",
      "Epoch [9/50], Step [100/600], Loss: 0.3013\n",
      "Epoch [9/50], Step [200/600], Loss: 0.4528\n",
      "Epoch [9/50], Step [300/600], Loss: 0.3904\n",
      "Epoch [9/50], Step [400/600], Loss: 0.3923\n",
      "Epoch [9/50], Step [500/600], Loss: 0.3924\n",
      "Epoch [9/50], Step [600/600], Loss: 0.3830\n",
      "Epoch [10/50], Step [100/600], Loss: 0.2912\n",
      "Epoch [10/50], Step [200/600], Loss: 0.3191\n",
      "Epoch [10/50], Step [300/600], Loss: 0.4804\n",
      "Epoch [10/50], Step [400/600], Loss: 0.4248\n",
      "Epoch [10/50], Step [500/600], Loss: 0.3835\n",
      "Epoch [10/50], Step [600/600], Loss: 0.3415\n",
      "Epoch [11/50], Step [100/600], Loss: 0.3236\n",
      "Epoch [11/50], Step [200/600], Loss: 0.3144\n",
      "Epoch [11/50], Step [300/600], Loss: 0.2562\n",
      "Epoch [11/50], Step [400/600], Loss: 0.3291\n",
      "Epoch [11/50], Step [500/600], Loss: 0.3653\n",
      "Epoch [11/50], Step [600/600], Loss: 0.3937\n",
      "Epoch [12/50], Step [100/600], Loss: 0.3648\n",
      "Epoch [12/50], Step [200/600], Loss: 0.3309\n",
      "Epoch [12/50], Step [300/600], Loss: 0.3441\n",
      "Epoch [12/50], Step [400/600], Loss: 0.2569\n",
      "Epoch [12/50], Step [500/600], Loss: 0.3671\n",
      "Epoch [12/50], Step [600/600], Loss: 0.3393\n",
      "Epoch [13/50], Step [100/600], Loss: 0.3057\n",
      "Epoch [13/50], Step [200/600], Loss: 0.2855\n",
      "Epoch [13/50], Step [300/600], Loss: 0.3892\n",
      "Epoch [13/50], Step [400/600], Loss: 0.3385\n",
      "Epoch [13/50], Step [500/600], Loss: 0.2432\n",
      "Epoch [13/50], Step [600/600], Loss: 0.4285\n",
      "Epoch [14/50], Step [100/600], Loss: 0.4860\n",
      "Epoch [14/50], Step [200/600], Loss: 0.3679\n",
      "Epoch [14/50], Step [300/600], Loss: 0.4043\n",
      "Epoch [14/50], Step [400/600], Loss: 0.2607\n",
      "Epoch [14/50], Step [500/600], Loss: 0.4439\n",
      "Epoch [14/50], Step [600/600], Loss: 0.4765\n",
      "Epoch [15/50], Step [100/600], Loss: 0.4357\n",
      "Epoch [15/50], Step [200/600], Loss: 0.3190\n",
      "Epoch [15/50], Step [300/600], Loss: 0.3321\n",
      "Epoch [15/50], Step [400/600], Loss: 0.4445\n",
      "Epoch [15/50], Step [500/600], Loss: 0.4097\n",
      "Epoch [15/50], Step [600/600], Loss: 0.4146\n",
      "Epoch [16/50], Step [100/600], Loss: 0.3616\n",
      "Epoch [16/50], Step [200/600], Loss: 0.4044\n",
      "Epoch [16/50], Step [300/600], Loss: 0.2580\n",
      "Epoch [16/50], Step [400/600], Loss: 0.2970\n",
      "Epoch [16/50], Step [500/600], Loss: 0.4228\n",
      "Epoch [16/50], Step [600/600], Loss: 0.3936\n",
      "Epoch [17/50], Step [100/600], Loss: 0.3855\n",
      "Epoch [17/50], Step [200/600], Loss: 0.3418\n",
      "Epoch [17/50], Step [300/600], Loss: 0.3283\n",
      "Epoch [17/50], Step [400/600], Loss: 0.3504\n",
      "Epoch [17/50], Step [500/600], Loss: 0.4182\n",
      "Epoch [17/50], Step [600/600], Loss: 0.3800\n",
      "Epoch [18/50], Step [100/600], Loss: 0.4819\n",
      "Epoch [18/50], Step [200/600], Loss: 0.3965\n",
      "Epoch [18/50], Step [300/600], Loss: 0.3657\n",
      "Epoch [18/50], Step [400/600], Loss: 0.3783\n",
      "Epoch [18/50], Step [500/600], Loss: 0.2954\n",
      "Epoch [18/50], Step [600/600], Loss: 0.3773\n",
      "Epoch [19/50], Step [100/600], Loss: 0.3931\n",
      "Epoch [19/50], Step [200/600], Loss: 0.2819\n",
      "Epoch [19/50], Step [300/600], Loss: 0.2788\n",
      "Epoch [19/50], Step [400/600], Loss: 0.4415\n",
      "Epoch [19/50], Step [500/600], Loss: 0.2865\n",
      "Epoch [19/50], Step [600/600], Loss: 0.4021\n",
      "Epoch [20/50], Step [100/600], Loss: 0.4152\n",
      "Epoch [20/50], Step [200/600], Loss: 0.4559\n",
      "Epoch [20/50], Step [300/600], Loss: 0.3690\n",
      "Epoch [20/50], Step [400/600], Loss: 0.3636\n",
      "Epoch [20/50], Step [500/600], Loss: 0.2332\n",
      "Epoch [20/50], Step [600/600], Loss: 0.5033\n",
      "Epoch [21/50], Step [100/600], Loss: 0.3849\n",
      "Epoch [21/50], Step [200/600], Loss: 0.3958\n",
      "Epoch [21/50], Step [300/600], Loss: 0.3133\n",
      "Epoch [21/50], Step [400/600], Loss: 0.2994\n",
      "Epoch [21/50], Step [500/600], Loss: 0.3278\n",
      "Epoch [21/50], Step [600/600], Loss: 0.3053\n",
      "Epoch [22/50], Step [100/600], Loss: 0.2986\n",
      "Epoch [22/50], Step [200/600], Loss: 0.1696\n",
      "Epoch [22/50], Step [300/600], Loss: 0.2654\n",
      "Epoch [22/50], Step [400/600], Loss: 0.3210\n",
      "Epoch [22/50], Step [500/600], Loss: 0.3451\n",
      "Epoch [22/50], Step [600/600], Loss: 0.2644\n",
      "Epoch [23/50], Step [100/600], Loss: 0.4321\n",
      "Epoch [23/50], Step [200/600], Loss: 0.3875\n",
      "Epoch [23/50], Step [300/600], Loss: 0.3747\n",
      "Epoch [23/50], Step [400/600], Loss: 0.2759\n",
      "Epoch [23/50], Step [500/600], Loss: 0.4604\n",
      "Epoch [23/50], Step [600/600], Loss: 0.3996\n",
      "Epoch [24/50], Step [100/600], Loss: 0.2944\n",
      "Epoch [24/50], Step [200/600], Loss: 0.2608\n",
      "Epoch [24/50], Step [300/600], Loss: 0.3294\n",
      "Epoch [24/50], Step [400/600], Loss: 0.3041\n",
      "Epoch [24/50], Step [500/600], Loss: 0.2419\n",
      "Epoch [24/50], Step [600/600], Loss: 0.3539\n",
      "Epoch [25/50], Step [100/600], Loss: 0.2258\n",
      "Epoch [25/50], Step [200/600], Loss: 0.1607\n",
      "Epoch [25/50], Step [300/600], Loss: 0.3874\n",
      "Epoch [25/50], Step [400/600], Loss: 0.3581\n",
      "Epoch [25/50], Step [500/600], Loss: 0.3295\n",
      "Epoch [25/50], Step [600/600], Loss: 0.2240\n",
      "Epoch [26/50], Step [100/600], Loss: 0.3777\n",
      "Epoch [26/50], Step [200/600], Loss: 0.3989\n",
      "Epoch [26/50], Step [300/600], Loss: 0.2884\n",
      "Epoch [26/50], Step [400/600], Loss: 0.4010\n",
      "Epoch [26/50], Step [500/600], Loss: 0.3840\n",
      "Epoch [26/50], Step [600/600], Loss: 0.4372\n",
      "Epoch [27/50], Step [100/600], Loss: 0.3652\n",
      "Epoch [27/50], Step [200/600], Loss: 0.4083\n",
      "Epoch [27/50], Step [300/600], Loss: 0.3934\n",
      "Epoch [27/50], Step [400/600], Loss: 0.1896\n",
      "Epoch [27/50], Step [500/600], Loss: 0.3242\n",
      "Epoch [27/50], Step [600/600], Loss: 0.3330\n",
      "Epoch [28/50], Step [100/600], Loss: 0.3125\n",
      "Epoch [28/50], Step [200/600], Loss: 0.5682\n",
      "Epoch [28/50], Step [300/600], Loss: 0.3858\n",
      "Epoch [28/50], Step [400/600], Loss: 0.1962\n",
      "Epoch [28/50], Step [500/600], Loss: 0.2626\n",
      "Epoch [28/50], Step [600/600], Loss: 0.2893\n",
      "Epoch [29/50], Step [100/600], Loss: 0.3546\n",
      "Epoch [29/50], Step [200/600], Loss: 0.1549\n",
      "Epoch [29/50], Step [300/600], Loss: 0.2461\n",
      "Epoch [29/50], Step [400/600], Loss: 0.2166\n",
      "Epoch [29/50], Step [500/600], Loss: 0.2649\n",
      "Epoch [29/50], Step [600/600], Loss: 0.2953\n",
      "Epoch [30/50], Step [100/600], Loss: 0.3046\n",
      "Epoch [30/50], Step [200/600], Loss: 0.4554\n",
      "Epoch [30/50], Step [300/600], Loss: 0.2199\n",
      "Epoch [30/50], Step [400/600], Loss: 0.3833\n",
      "Epoch [30/50], Step [500/600], Loss: 0.2415\n",
      "Epoch [30/50], Step [600/600], Loss: 0.3476\n",
      "Epoch [31/50], Step [100/600], Loss: 0.3076\n",
      "Epoch [31/50], Step [200/600], Loss: 0.2984\n",
      "Epoch [31/50], Step [300/600], Loss: 0.2254\n",
      "Epoch [31/50], Step [400/600], Loss: 0.3568\n",
      "Epoch [31/50], Step [500/600], Loss: 0.2831\n",
      "Epoch [31/50], Step [600/600], Loss: 0.2963\n",
      "Epoch [32/50], Step [100/600], Loss: 0.3060\n",
      "Epoch [32/50], Step [200/600], Loss: 0.2686\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [32/50], Step [300/600], Loss: 0.3258\n",
      "Epoch [32/50], Step [400/600], Loss: 0.4812\n",
      "Epoch [32/50], Step [500/600], Loss: 0.2824\n",
      "Epoch [32/50], Step [600/600], Loss: 0.3724\n",
      "Epoch [33/50], Step [100/600], Loss: 0.2758\n",
      "Epoch [33/50], Step [200/600], Loss: 0.2832\n",
      "Epoch [33/50], Step [300/600], Loss: 0.3522\n",
      "Epoch [33/50], Step [400/600], Loss: 0.2733\n",
      "Epoch [33/50], Step [500/600], Loss: 0.4449\n",
      "Epoch [33/50], Step [600/600], Loss: 0.2772\n",
      "Epoch [34/50], Step [100/600], Loss: 0.2931\n",
      "Epoch [34/50], Step [200/600], Loss: 0.3721\n",
      "Epoch [34/50], Step [300/600], Loss: 0.2111\n",
      "Epoch [34/50], Step [400/600], Loss: 0.2009\n",
      "Epoch [34/50], Step [500/600], Loss: 0.4580\n",
      "Epoch [34/50], Step [600/600], Loss: 0.2539\n",
      "Epoch [35/50], Step [100/600], Loss: 0.4797\n",
      "Epoch [35/50], Step [200/600], Loss: 0.4525\n",
      "Epoch [35/50], Step [300/600], Loss: 0.4796\n",
      "Epoch [35/50], Step [400/600], Loss: 0.3748\n",
      "Epoch [35/50], Step [500/600], Loss: 0.2849\n",
      "Epoch [35/50], Step [600/600], Loss: 0.2594\n",
      "Epoch [36/50], Step [100/600], Loss: 0.3621\n",
      "Epoch [36/50], Step [200/600], Loss: 0.6072\n",
      "Epoch [36/50], Step [300/600], Loss: 0.3753\n",
      "Epoch [36/50], Step [400/600], Loss: 0.2835\n",
      "Epoch [36/50], Step [500/600], Loss: 0.2412\n",
      "Epoch [36/50], Step [600/600], Loss: 0.3269\n",
      "Epoch [37/50], Step [100/600], Loss: 0.2129\n",
      "Epoch [37/50], Step [200/600], Loss: 0.3244\n",
      "Epoch [37/50], Step [300/600], Loss: 0.2439\n",
      "Epoch [37/50], Step [400/600], Loss: 0.3125\n",
      "Epoch [37/50], Step [500/600], Loss: 0.3756\n",
      "Epoch [37/50], Step [600/600], Loss: 0.3183\n",
      "Epoch [38/50], Step [100/600], Loss: 0.4112\n",
      "Epoch [38/50], Step [200/600], Loss: 0.3291\n",
      "Epoch [38/50], Step [300/600], Loss: 0.3535\n",
      "Epoch [38/50], Step [400/600], Loss: 0.3750\n",
      "Epoch [38/50], Step [500/600], Loss: 0.3487\n",
      "Epoch [38/50], Step [600/600], Loss: 0.2554\n",
      "Epoch [39/50], Step [100/600], Loss: 0.3574\n",
      "Epoch [39/50], Step [200/600], Loss: 0.3078\n",
      "Epoch [39/50], Step [300/600], Loss: 0.3061\n",
      "Epoch [39/50], Step [400/600], Loss: 0.3448\n",
      "Epoch [39/50], Step [500/600], Loss: 0.2217\n",
      "Epoch [39/50], Step [600/600], Loss: 0.2808\n",
      "Epoch [40/50], Step [100/600], Loss: 0.3113\n",
      "Epoch [40/50], Step [200/600], Loss: 0.2598\n",
      "Epoch [40/50], Step [300/600], Loss: 0.2262\n",
      "Epoch [40/50], Step [400/600], Loss: 0.2985\n",
      "Epoch [40/50], Step [500/600], Loss: 0.2765\n",
      "Epoch [40/50], Step [600/600], Loss: 0.4362\n",
      "Epoch [41/50], Step [100/600], Loss: 0.3307\n",
      "Epoch [41/50], Step [200/600], Loss: 0.2460\n",
      "Epoch [41/50], Step [300/600], Loss: 0.4647\n",
      "Epoch [41/50], Step [400/600], Loss: 0.3705\n",
      "Epoch [41/50], Step [500/600], Loss: 0.2340\n",
      "Epoch [41/50], Step [600/600], Loss: 0.2717\n",
      "Epoch [42/50], Step [100/600], Loss: 0.2973\n",
      "Epoch [42/50], Step [200/600], Loss: 0.3092\n",
      "Epoch [42/50], Step [300/600], Loss: 0.2002\n",
      "Epoch [42/50], Step [400/600], Loss: 0.2661\n",
      "Epoch [42/50], Step [500/600], Loss: 0.3200\n",
      "Epoch [42/50], Step [600/600], Loss: 0.3225\n",
      "Epoch [43/50], Step [100/600], Loss: 0.2881\n",
      "Epoch [43/50], Step [200/600], Loss: 0.1832\n",
      "Epoch [43/50], Step [300/600], Loss: 0.3889\n",
      "Epoch [43/50], Step [400/600], Loss: 0.3222\n",
      "Epoch [43/50], Step [500/600], Loss: 0.3046\n",
      "Epoch [43/50], Step [600/600], Loss: 0.2200\n",
      "Epoch [44/50], Step [100/600], Loss: 0.1999\n",
      "Epoch [44/50], Step [200/600], Loss: 0.3094\n",
      "Epoch [44/50], Step [300/600], Loss: 0.2435\n",
      "Epoch [44/50], Step [400/600], Loss: 0.1695\n",
      "Epoch [44/50], Step [500/600], Loss: 0.2352\n",
      "Epoch [44/50], Step [600/600], Loss: 0.2828\n",
      "Epoch [45/50], Step [100/600], Loss: 0.4066\n",
      "Epoch [45/50], Step [200/600], Loss: 0.3528\n",
      "Epoch [45/50], Step [300/600], Loss: 0.2249\n",
      "Epoch [45/50], Step [400/600], Loss: 0.4053\n",
      "Epoch [45/50], Step [500/600], Loss: 0.4069\n",
      "Epoch [45/50], Step [600/600], Loss: 0.3302\n",
      "Epoch [46/50], Step [100/600], Loss: 0.1800\n",
      "Epoch [46/50], Step [200/600], Loss: 0.3548\n",
      "Epoch [46/50], Step [300/600], Loss: 0.3810\n",
      "Epoch [46/50], Step [400/600], Loss: 0.1716\n",
      "Epoch [46/50], Step [500/600], Loss: 0.4306\n",
      "Epoch [46/50], Step [600/600], Loss: 0.3433\n",
      "Epoch [47/50], Step [100/600], Loss: 0.2663\n",
      "Epoch [47/50], Step [200/600], Loss: 0.2200\n",
      "Epoch [47/50], Step [300/600], Loss: 0.3525\n",
      "Epoch [47/50], Step [400/600], Loss: 0.3263\n",
      "Epoch [47/50], Step [500/600], Loss: 0.1479\n",
      "Epoch [47/50], Step [600/600], Loss: 0.3332\n",
      "Epoch [48/50], Step [100/600], Loss: 0.3506\n",
      "Epoch [48/50], Step [200/600], Loss: 0.2761\n",
      "Epoch [48/50], Step [300/600], Loss: 0.1719\n",
      "Epoch [48/50], Step [400/600], Loss: 0.3968\n",
      "Epoch [48/50], Step [500/600], Loss: 0.2495\n",
      "Epoch [48/50], Step [600/600], Loss: 0.5562\n",
      "Epoch [49/50], Step [100/600], Loss: 0.4218\n",
      "Epoch [49/50], Step [200/600], Loss: 0.3255\n",
      "Epoch [49/50], Step [300/600], Loss: 0.2449\n",
      "Epoch [49/50], Step [400/600], Loss: 0.2814\n",
      "Epoch [49/50], Step [500/600], Loss: 0.3569\n",
      "Epoch [49/50], Step [600/600], Loss: 0.2432\n",
      "Epoch [50/50], Step [100/600], Loss: 0.3104\n",
      "Epoch [50/50], Step [200/600], Loss: 0.3618\n",
      "Epoch [50/50], Step [300/600], Loss: 0.2986\n",
      "Epoch [50/50], Step [400/600], Loss: 0.3923\n",
      "Epoch [50/50], Step [500/600], Loss: 0.3213\n",
      "Epoch [50/50], Step [600/600], Loss: 0.3265\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "\n",
    "total_step = len(train_loader)\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    \n",
    "    for i, (images, labels) in enumerate(train_loader):\n",
    "        \n",
    "        images = images.reshape(-1, input_size)\n",
    "        \n",
    "        \n",
    "        # forward pass\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        \n",
    "        # optimize and backward\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        if (i+1) % 100 == 0:\n",
    "            print ('Epoch [{}/{}], Step [{}/{}], Loss: {:.4f}' \n",
    "                   .format(epoch+1, num_epochs, i+1, total_step, loss.item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), 'model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the model on the 10000 test images: 91.8499984741211 %\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    total = 0\n",
    "    correct = 0\n",
    "    \n",
    "    for images, labels in test_loader:\n",
    "        images = images.reshape(-1, input_size)\n",
    "        \n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum()\n",
    "\n",
    "    print('Accuracy of the model on the 10000 test images: {} %'.format(100 * correct / total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
